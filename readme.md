
project
    code 我们使用mmdet作为训练框架，使用里面的co-detr作为基础模型
        condigs 里面是是训练配置和推理配置
        mmdet 里面是模型各个框架代码
        tools 里面的代码时将初始权重变成双流模型
        dist_train.sh 分布式训练启动脚本
        test.py 推理脚本
        train.py 训练脚本
    data
        pretrain_model 这里需要下载vit官方初始化权重，我放到自己华为云链接，直接wget https://shixi-1.obs.cn-north-4.myhuaweicloud.com/co_dino_5scale_vit_large_coco.pth
        contest_data 官方数据
        三个pth权重，用于测试最好的成绩，进行wbf推理
    make_merge_test 用于生成融合配准的rgb图像
    index.py 最好成绩推理脚本
    init.sh 环境构建脚本
    test.sh 运行推理
    train.sh 运行训练
    wbf.py 模型融合代码
==========运行过程中会产生4个json文件，然后最终json放在data/result/result.json文件下
========== 注意，这个版本需要在有网络情况下才能运行，部分模型可能有依赖需要下载，
==========注意，如果想要更方便的跑通推理，可以专门下载我官方打包提交的推理版本，在官方镜像上，直接跑通

# 代码说明

## 训练配置（必选）
- 硬件配置：8卡A100/A800（80G显存）
- 训练花费时长：共2天（模型1：12h, 模型2：12h，模型3：24h）；相关配置文件详见train.sh。

## 环境配置（必选）
- 详见init.sh注释说明

## 数据（必选）
- 仅使用了本次比赛提供的训练数据

## 预训练模型（必选）
- 仅使用了Co-DETR作者开源的ViT预训练权重，下载地址：https://drive.google.com/drive/folders/1-vAVIHHJ6Gyw0E6mGdbjdZ1hjkEdo3Rt

## 算法（必选）

### 整体思路介绍（必选）
- 网络选型方面，使用了在COCO数据集上接近SOTA的模型Co-DETR，相比DETR检测器增加了多个并行辅助头部以及多种标签分配方式，增加了与gt匹配的正样本数量，提高了编码器在端到端检测器中的学习能力；主干网络使用了改进后的ViT-L结构，在neck部分增加了多尺度输出，取得了优于Swin Transformer的精度；
- 在可见光和红外光双光融合的部分，采用了上限更高的特征级融合的方法，使用包含相同backbone的双路结构分别提取可见光和红外光输入图像的特征，并在neck输入侧进行特征融合，融合后保持和原始目标检测网络相同的tensor维度，再送入单路的neck和head进行目标的分类和回归；
- 模型训练尺寸使用640输入，和原图尺寸一致，更大的输入尺寸并没有保留更多的有效信息，对于最终结果也不会带来稳定的收益；


### 方法的创新点（如果有）
- 训练时，在检测框架中增加auto augmentv1的数据增强方法，在训练阶段会随机选择2~3种数据增强方法的组合，在单光和双光两种模态下模型精度显著提升，优于yolo系列中常规的mosaic/mixup/scale/hsv增强的pipeline，以及简单的Resize/Crop/Flip数据增强pipeline组合；实验证明过于复杂的数据增强组合可能会破坏原始的数据分布，而过于简单的增强方法又会出现模型泛化性显著降低的问题；另外为了防止仿射变换类操作不一致导致双光样本出现错位的情况，决定对两种模态的样本进行完全相同的数据增强：即先通过random确定是否执行数据增强，再通过random产生实际增强的数值，最后对两种模态的图像统一执行相同的增强操作；
- 在双光融合模块部分引入了transformer，基于transformer强大的全局建模和上下文提取能力，让模型具备关注重要特征的能力；同时在融合时设置了可学习的参数，取代常规的1:1比例特征融合或者直接对不同模态特征进行concat的做法；同时，对于红外光和可见光的特征，分别使用另一模态的特征作为queries进行双向交叉注意力融合，最终取得了优于可见光向红外光模态单向融合的结果；
- 训练阶段采用了类别均衡采样策略（ClassBalancedDataset），对所有训练样本中出现概率小于0.2的类别进行重采样，从而一定程度上缓解了长尾问题；
- 对于常规目标检测的预训练模型进行预处理，将backbone和neck部分对应的key分别复制一份给到可见光和红外光的特征提取部分对应的key，同时保持value不变，从而加速网络收敛；
- 模型推理阶段，仅使用上述单模型、单尺度已经可以取得B榜第一的成绩；在此基础上，使用wbf融合策略，单模型后处理方式修改为全部使用nms，并额外引入了640尺寸输入、配合auto augmentv2数据增强方法训练的模型2，以及使用1280尺寸输入、配合augo augmentv1数据增强方法训练的模型3，最终在满足官方推理耗时要求的前提下，进一步将模型精度提升了2%以上；在多数队伍B榜精度相比A榜精度降低3~5%前提下，单模型相比A榜仅下降0.8%，wbf后相比A榜精度反而提升了0.2%，证明了模型在新数据上展现出很好的泛化能力；

### 网络结构
- 检测部分参考论文《Co-DETR》
- 融合部分参考论文《ICAFusion》

### 损失函数
- 分类损失：CrossEntropyLoss
- 回归损失：GIoULoss

### 数据扩增
- 详见创新点部分

### 模型集成
- 详见创新点部分

## 训练流程（必选）
- 详见train.sh注释说明

## 测试流程（必选）
TODO

## 其他注意事项
- 验证数据的划分保持和官方一致
